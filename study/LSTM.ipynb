{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Skip linksSkip to Contentplay Live Show naviga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>play videoplay videoVideo Duration 02 minutes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A major bone of contention between negotiator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A final round of talks is scheduled to be hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Keep reading list of 4 itemslist 1 of 4Japanes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0\n",
       "0           0  Skip linksSkip to Contentplay Live Show naviga...\n",
       "1           1  play videoplay videoVideo Duration 02 minutes ...\n",
       "2           2   A major bone of contention between negotiator...\n",
       "3           3   A final round of talks is scheduled to be hel...\n",
       "4           4  Keep reading list of 4 itemslist 1 of 4Japanes..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'/home/kar7mp5/Projects/MinGPT/data/article_contents/environment_8.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열의 개수:  2\n",
      "Index(['Unnamed: 0', '0'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('열의 개수: ', len(df.columns))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df['0'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Skip linksSkip to Contentplay Live Show navigation menuNavigation menuNewsShow more news sectionsMiddle EastAfricaAsiaUS & CanadaLatin AmericaEuropeAsia PacificIsrael War on GazaFeaturesOpinionVideoMoreShow more sectionsEconomyUkraine warCoronavirusClimate CrisisInvestigationsInteractivesIn PicturesScience & TechnologySportPodcastsplay Live Click here to searchsearchEXPLAINERNews|EnvironmentInvisible plastic: Why banning plastic bags will never be enoughHow ordinary items like toothpaste and teabags could actually be damaging our environment',\n",
       " 'play videoplay videoVideo Duration 02 minutes 37 seconds 02:37By\\xa0Sarah ShamimPublished On 4 May 20244 May 2024This week, the fourth round of treaty talks by the Intergovernmental Negotiating Committee on Plastic Pollution concluded in Ottawa, Canada',\n",
       " ' A major bone of contention between negotiators from 175 countries is whether or not to limit the production of plastic, most of which is made from fossil fuels and chemicals and which causes pollution after use, as it does not fully or easily biodegrade',\n",
       " ' A final round of talks is scheduled to be held in South Korea at the end of this year',\n",
       " 'Keep reading list of 4 itemslist 1 of 4Japanese scientists find microplastics are present in cloudslist 2 of 4Finding a fix: Nigerian women lead drive to upcycle plasticslist 3 of 4Is the world capable of stopping a climate apocalypse?list 4 of 4Is Israel’s Gaza bombing also a war on the climate?end of listAmid global struggles to curb plastic pollution, the United Kingdom said last month that it would introduce legislation to ban wet wipes which contain plastic',\n",
       " ' Wet wipes made with plastic have been shown to leach harmful microplastics into the environment after they have been disposed of',\n",
       " 'Everyone knows that plastic bags are a blight on the environment, but what other everyday items – also known as “invisible plastics – unexpectedly contain plastic or harmful “microplastics” and is there a solution?What are invisible plastics and ‘microplastics’?These are items which are seemingly not made of plastic – such as wet wipes – but which, once disposed of, release plastic into the environment',\n",
       " '“Invisible plastics are everywhere,” Tony Walker, a professor at the School for Resource and Environmental Studies at Dalhousie University in Canada who also belongs to the Scientists’ Coalition for an Effective Plastics Treaty, said',\n",
       " '“In terms of global plastic production, which includes things like the table I’m sat at, the chair I’m sat on, my computer – you name it, it probably contains a plastic of some kind',\n",
       " '”Not all plastic needs to be eliminated, he said, particularly if it is used to make furniture which could last for several decades',\n",
       " ' These are adding to the “tonnes of plastic that are sitting in our landfills”, he said, often leaching harmful microplastics into the environment',\n",
       " 'Microplastics are tiny particles of plastic which can even make their way into our food – for example by first being broken down and ingested by fish when they get into the sea',\n",
       " ' Walker added that even so-called “biodegradable plastic”, which is advertised as being able to break down naturally once disposed of, can contain microplastics',\n",
       " 'Plastic can break down into microplastics in the sea, and enter the food chain ShutterstockWhich unexpected items could contain plastic?Some other everyday items which surprisingly contain plastic are:Chewing gum: A key ingredient used in making chewing gum – “gum base” – actually contains polyvinyl acetate, a plastic which does not biodegrade once the gum is disposed of',\n",
       " 'Tea bags: To retain their shape while they are in hot water, most tea bags are lined with a plastic called polypropylene',\n",
       " 'Sunscreen:\\xa0Several brands of sunscreen use microplastics as an ingredient in their formula',\n",
       " 'Aluminium cans: Many aluminium cans that contain soda have a lining of plastic to prevent the acid from the soda from reacting with the metal of the can',\n",
       " 'Receipts:\\xa0Many receipts are printed on thermal paper, which is coated with a layer of plastic to give it a shiny finish, making most paper receipts non-recyclable',\n",
       " 'Toiletries and laundry products: Some toothpaste brands contain tiny beads or micro-beads of plastic which act as exfoliants',\n",
       " ' Micro-beads can also be found in facial scrubs, makeup products and laundry detergent powders',\n",
       " '  What are countries doing about this problem?During a session of the United Nations Environment Assembly in March 2022, a landmark resolution was adopted to draft an international legally binding treaty on plastic pollution',\n",
       " 'Under the resolution, an intergovernmental negotiating committee INC including representatives from 175 countries, has been holding talks with the aim of drafting a treaty by the end of this year',\n",
       " ' The fourth session wrapped up this week in Canada and the last one will be held between November and December in South Korea',\n",
       " 'Environmental experts say it is crucial that they reach an agreement on this issue',\n",
       " ' Plastic production continues to rise around the world and the annual production of fossil fuel-based plastic is projected by the Organisation for Economic Co-operation and Development OECD to triple by 2060 if nothing changes',\n",
       " 'The head of Greenpeace in Ottawa, Graham Forbes, said that it will be impossible to end plastic pollution without massively reducing plastic production',\n",
       " ' “However, we’re recycling on average as a planet, only 9 percent',\n",
       " '”  Why don’t some countries want to reduce plastic production?This is mainly down to economic factors, experts say',\n",
       " ' These countries believe that stopping the production of plastic would hurt their economies, he added',\n",
       " 'Will governments find a solution?Experts are calling on countries represented at the INC to work much harder to reach a consensus on the production of plastic before the end of this year',\n",
       " 'Walker pointed out that plastic is a transboundary pollutant, crossing rivers and borders, meaning countries should have a vested interest in tackling this issue',\n",
       " ' “Plastics are now in the atmosphere, in the air we breathe, so they’re actually travelling between continents on air currents,” said Walker',\n",
       " 'Source: Al Jazeeraaj-logoaj-logoaj-logoAboutShow moreAbout UsCode of EthicsTerms and ConditionsEUEEA Regulatory NoticePrivacy PolicyCookie PolicyCookie PreferencesSitemapWork for usHR QualityConnectShow moreContact UsUser Accounts HelpAdvertise with usAppsNewslettersChannel FinderTV SchedulePodcastsSubmit a TipOur ChannelsShow moreAl Jazeera ArabicAl Jazeera EnglishAl Jazeera Investigative UnitAl Jazeera MubasherAl Jazeera DocumentaryAl Jazeera BalkansAJ+Our NetworkShow moreAl Jazeera Centre for StudiesAl Jazeera Media InstituteLearn ArabicAl Jazeera Centre for Public Liberties & Human RightsAl Jazeera ForumAl Jazeera Hotel PartnersFollow Al Jazeera English:facebooktwitteryoutubeinstagram-colored-outlinerss© 2024 Al Jazeera Media Network']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = []\n",
    "# 헤드라인의 값들을 리스트로 저장\n",
    "headline.extend(list(df['0']))\n",
    "headline[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 33\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수 : {}'.format(len(headline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노이즈값 제거 후 샘플의 개수 : 33\n"
     ]
    }
   ],
   "source": [
    "headline = [word for word in headline if word != \"Unknown\"]\n",
    "print(\"노이즈값 제거 후 샘플의 개수 : {}\".format(len(headline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Skip linksSkip to Contentplay Live Show navigation menuNavigation menuNewsShow more news sectionsMiddle EastAfricaAsiaUS & CanadaLatin AmericaEuropeAsia PacificIsrael War on GazaFeaturesOpinionVideoMoreShow more sectionsEconomyUkraine warCoronavirusClimate CrisisInvestigationsInteractivesIn PicturesScience & TechnologySportPodcastsplay Live Click here to searchsearchEXPLAINERNews|EnvironmentInvisible plastic: Why banning plastic bags will never be enoughHow ordinary items like toothpaste and teabags could actually be damaging our environment',\n",
       " 'play videoplay videoVideo Duration 02 minutes 37 seconds 02:37By\\xa0Sarah ShamimPublished On 4 May 20244 May 2024This week, the fourth round of treaty talks by the Intergovernmental Negotiating Committee on Plastic Pollution concluded in Ottawa, Canada',\n",
       " ' A major bone of contention between negotiators from 175 countries is whether or not to limit the production of plastic, most of which is made from fossil fuels and chemicals and which causes pollution after use, as it does not fully or easily biodegrade',\n",
       " ' A final round of talks is scheduled to be held in South Korea at the end of this year',\n",
       " 'Keep reading list of 4 itemslist 1 of 4Japanese scientists find microplastics are present in cloudslist 2 of 4Finding a fix: Nigerian women lead drive to upcycle plasticslist 3 of 4Is the world capable of stopping a climate apocalypse?list 4 of 4Is Israel’s Gaza bombing also a war on the climate?end of listAmid global struggles to curb plastic pollution, the United Kingdom said last month that it would introduce legislation to ban wet wipes which contain plastic']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skip linksskip to contentplay live show navigation menunavigation menunewsshow more news sectionsmiddle eastafricaasiaus  canadalatin americaeuropeasia pacificisrael war on gazafeaturesopinionvideomoreshow more sectionseconomyukraine warcoronavirusclimate crisisinvestigationsinteractivesin picturesscience  technologysportpodcastsplay live click here to searchsearchexplainernewsenvironmentinvisible plastic why banning plastic bags will never be enoughhow ordinary items like toothpaste and teabags could actually be damaging our environment',\n",
       " 'play videoplay videovideo duration 02 minutes 37 seconds 0237bysarah shamimpublished on 4 may 20244 may 2024this week the fourth round of treaty talks by the intergovernmental negotiating committee on plastic pollution concluded in ottawa canada',\n",
       " ' a major bone of contention between negotiators from 175 countries is whether or not to limit the production of plastic most of which is made from fossil fuels and chemicals and which causes pollution after use as it does not fully or easily biodegrade',\n",
       " ' a final round of talks is scheduled to be held in south korea at the end of this year',\n",
       " 'keep reading list of 4 itemslist 1 of 4japanese scientists find microplastics are present in cloudslist 2 of 4finding a fix nigerian women lead drive to upcycle plasticslist 3 of 4is the world capable of stopping a climate apocalypselist 4 of 4is israels gaza bombing also a war on the climateend of listamid global struggles to curb plastic pollution the united kingdom said last month that it would introduce legislation to ban wet wipes which contain plastic']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "def repreprocessing(raw_sentence):\n",
    "    if isinstance(raw_sentence, float):\n",
    "        # 부동 소수점일 경우 처리할 내용 추가\n",
    "        return \"\"\n",
    "\n",
    "    preproceseed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\", \"ignore\")\n",
    "    # 구두점 제거와 동시에 소문자화\n",
    "    return \"\".join(word for word in preproceseed_sentence if word not in punctuation).lower()\n",
    "\n",
    "preprocessed_headline = [repreprocessing(x) for x in headline if not isinstance(x, float)]\n",
    "preprocessed_headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 479\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_headline)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"단어 집합의 크기 : %d\" % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip linksskip to contentplay live show navigation menunavigation menunewsshow more news sectionsmiddle eastafricaasiaus  canadalatin americaeuropeasia pacificisrael war on gazafeaturesopinionvideomoreshow more sectionseconomyukraine warcoronavirusclimate crisisinvestigationsinteractivesin picturesscience  technologysportpodcastsplay live click here to searchsearchexplainernewsenvironmentinvisible plastic why banning plastic bags will never be enoughhow ordinary items like toothpaste and teabags could actually be damaging our environment\n",
      "play videoplay videovideo duration 02 minutes 37 seconds 0237bysarah shamimpublished on 4 may 20244 may 2024this week the fourth round of treaty talks by the intergovernmental negotiating committee on plastic pollution concluded in ottawa canada\n",
      " a major bone of contention between negotiators from 175 countries is whether or not to limit the production of plastic most of which is made from fossil fuels and chemicals and which causes pollution after use as it does not fully or easily biodegrade\n",
      " a final round of talks is scheduled to be held in south korea at the end of this year\n",
      "keep reading list of 4 itemslist 1 of 4japanese scientists find microplastics are present in cloudslist 2 of 4finding a fix nigerian women lead drive to upcycle plasticslist 3 of 4is the world capable of stopping a climate apocalypselist 4 of 4is israels gaza bombing also a war on the climateend of listamid global struggles to curb plastic pollution the united kingdom said last month that it would introduce legislation to ban wet wipes which contain plastic\n",
      " wet wipes made with plastic have been shown to leach harmful microplastics into the environment after they have been disposed of\n",
      "everyone knows that plastic bags are a blight on the environment but what other everyday items  also known as invisible plastics  unexpectedly contain plastic or harmful microplastics and is there a solutionwhat are invisible plastics and microplasticsthese are items which are seemingly not made of plastic  such as wet wipes  but which once disposed of release plastic into the environment\n",
      "invisible plastics are everywhere tony walker a professor at the school for resource and environmental studies at dalhousie university in canada who also belongs to the scientists coalition for an effective plastics treaty said\n",
      "in terms of global plastic production which includes things like the table im sat at the chair im sat on my computer  you name it it probably contains a plastic of some kind\n",
      "not all plastic needs to be eliminated he said particularly if it is used to make furniture which could last for several decades\n",
      " these are adding to the tonnes of plastic that are sitting in our landfills he said often leaching harmful microplastics into the environment\n",
      "microplastics are tiny particles of plastic which can even make their way into our food  for example by first being broken down and ingested by fish when they get into the sea\n",
      " walker added that even socalled biodegradable plastic which is advertised as being able to break down naturally once disposed of can contain microplastics\n",
      "plastic can break down into microplastics in the sea and enter the food chain shutterstockwhich unexpected items could contain plasticsome other everyday items which surprisingly contain plastic arechewing gum a key ingredient used in making chewing gum  gum base  actually contains polyvinyl acetate a plastic which does not biodegrade once the gum is disposed of\n",
      "tea bags to retain their shape while they are in hot water most tea bags are lined with a plastic called polypropylene\n",
      "sunscreenseveral brands of sunscreen use microplastics as an ingredient in their formula\n",
      "aluminium cans many aluminium cans that contain soda have a lining of plastic to prevent the acid from the soda from reacting with the metal of the can\n",
      "receiptsmany receipts are printed on thermal paper which is coated with a layer of plastic to give it a shiny finish making most paper receipts nonrecyclable\n",
      "toiletries and laundry products some toothpaste brands contain tiny beads or microbeads of plastic which act as exfoliants\n",
      " microbeads can also be found in facial scrubs makeup products and laundry detergent powders\n",
      "  what are countries doing about this problemduring a session of the united nations environment assembly in march 2022 a landmark resolution was adopted to draft an international legally binding treaty on plastic pollution\n",
      "under the resolution an intergovernmental negotiating committee inc including representatives from 175 countries has been holding talks with the aim of drafting a treaty by the end of this year\n",
      " the fourth session wrapped up this week in canada and the last one will be held between november and december in south korea\n",
      "environmental experts say it is crucial that they reach an agreement on this issue\n",
      " plastic production continues to rise around the world and the annual production of fossil fuelbased plastic is projected by the organisation for economic cooperation and development oecd to triple by 2060 if nothing changes\n",
      "the head of greenpeace in ottawa graham forbes said that it will be impossible to end plastic pollution without massively reducing plastic production\n",
      " however were recycling on average as a planet only 9 percent\n",
      "  why dont some countries want to reduce plastic productionthis is mainly down to economic factors experts say\n",
      " these countries believe that stopping the production of plastic would hurt their economies he added\n",
      "will governments find a solutionexperts are calling on countries represented at the inc to work much harder to reach a consensus on the production of plastic before the end of this year\n",
      "walker pointed out that plastic is a transboundary pollutant crossing rivers and borders meaning countries should have a vested interest in tackling this issue\n",
      " plastics are now in the atmosphere in the air we breathe so theyre actually travelling between continents on air currents said walker\n",
      "source al jazeeraajlogoajlogoajlogoaboutshow moreabout uscode of ethicsterms and conditionseueea regulatory noticeprivacy policycookie policycookie preferencessitemapwork for ushr qualityconnectshow morecontact ususer accounts helpadvertise with usappsnewsletterschannel findertv schedulepodcastssubmit a tipour channelsshow moreal jazeera arabical jazeera englishal jazeera investigative unital jazeera mubasheral jazeera documentaryal jazeera balkansajour networkshow moreal jazeera centre for studiesal jazeera media institutelearn arabical jazeera centre for public liberties  human rightsal jazeera forumal jazeera hotel partnersfollow al jazeera englishfacebooktwitteryoutubeinstagramcoloredoutlinerss 2024 al jazeera media network\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[145, 146],\n",
       " [145, 146, 4],\n",
       " [145, 146, 4, 147],\n",
       " [145, 146, 4, 147, 69],\n",
       " [145, 146, 4, 147, 69, 148],\n",
       " [145, 146, 4, 147, 69, 148, 149],\n",
       " [145, 146, 4, 147, 69, 148, 149, 150],\n",
       " [145, 146, 4, 147, 69, 148, 149, 150, 151],\n",
       " [145, 146, 4, 147, 69, 148, 149, 150, 151, 70],\n",
       " [145, 146, 4, 147, 69, 148, 149, 150, 151, 70, 152],\n",
       " [145, 146, 4, 147, 69, 148, 149, 150, 151, 70, 152, 153]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "for sentence in preprocessed_headline:\n",
    "    print(sentence)\n",
    "    # 각 샘플에 대한 정수 인코딩\n",
    "    encoded = tokenizer.texts_to_sequences([sentence])[0] \n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "sequences[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 582번 단어 : a\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "for key, value in tokenizer.word_index.items(): # 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
    "    index_to_word[value] = key\n",
    "\n",
    "print(\"빈도수 상위 582번 단어 : {}\".format(index_to_word[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 77\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "print(\"샘플의 최대 길이 : {}\".format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0 145 146]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 145 146   4]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 145 146   4 147]]\n"
     ]
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding=\"pre\")\n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0 145]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 145 146]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 145 146   4]]\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146   4 147]\n"
     ]
    }
   ],
   "source": [
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 - 3s - 100ms/step - accuracy: 0.0279 - loss: 6.0800\n",
      "Epoch 2/200\n",
      "31/31 - 1s - 46ms/step - accuracy: 0.0445 - loss: 5.7478\n",
      "Epoch 3/200\n",
      "31/31 - 1s - 47ms/step - accuracy: 0.0393 - loss: 5.6518\n",
      "Epoch 4/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0403 - loss: 5.6287\n",
      "Epoch 5/200\n",
      "31/31 - 1s - 45ms/step - accuracy: 0.0331 - loss: 5.6220\n",
      "Epoch 6/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0362 - loss: 5.6094\n",
      "Epoch 7/200\n",
      "31/31 - 1s - 45ms/step - accuracy: 0.0393 - loss: 5.5975\n",
      "Epoch 8/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0393 - loss: 5.5809\n",
      "Epoch 9/200\n",
      "31/31 - 1s - 46ms/step - accuracy: 0.0403 - loss: 5.5563\n",
      "Epoch 10/200\n",
      "31/31 - 1s - 42ms/step - accuracy: 0.0445 - loss: 5.5141\n",
      "Epoch 11/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0424 - loss: 5.4465\n",
      "Epoch 12/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0507 - loss: 5.3626\n",
      "Epoch 13/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0610 - loss: 5.2601\n",
      "Epoch 14/200\n",
      "31/31 - 1s - 43ms/step - accuracy: 0.0662 - loss: 5.1492\n",
      "Epoch 15/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0703 - loss: 5.0342\n",
      "Epoch 16/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0755 - loss: 4.9309\n",
      "Epoch 17/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0879 - loss: 4.8088\n",
      "Epoch 18/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0920 - loss: 4.6850\n",
      "Epoch 19/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.0972 - loss: 4.5752\n",
      "Epoch 20/200\n",
      "31/31 - 1s - 43ms/step - accuracy: 0.0972 - loss: 4.4591\n",
      "Epoch 21/200\n",
      "31/31 - 1s - 44ms/step - accuracy: 0.1107 - loss: 4.3467\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(vocab_size, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Projects/MinGPT/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_dim = 10\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/LSTM.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./model/LSTM.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "\n",
    "    # n번 반복\n",
    "    for _ in range(n):\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding=\"pre\")\n",
    "\n",
    "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items(): \n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        current_word = current_word + ' '  + word\n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi are countries countries countries countries countries countries countries countries countries countries shamimpublished on countries countries countries countries countries countries canadalatin canadalatin americaeuropeasia americaeuropeasia americaeuropeasia americaeuropeasia ususer picturesscience usappsnewsletterschannel usappsnewsletterschannel usappsnewsletterschannel jazeera media jazeera jazeera jazeera\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, \"hi\", 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump, Donald J are countries countries countries countries countries countries countries countries countries countries shamimpublished on countries countries countries countries countries countries canadalatin canadalatin americaeuropeasia americaeuropeasia americaeuropeasia americaeuropeasia ususer picturesscience usappsnewsletterschannel usappsnewsletterschannel usappsnewsletterschannel\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, \"Trump, Donald J\", 30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
